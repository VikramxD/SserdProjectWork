{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1><center>Overfitting Trees</center></h1>\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nfrom sklearn.tree import DecisionTreeRegressor\n\n# paste your get_features_targets function here\ndef get_features_targets(data):\n  features = np.zeros((data.shape[0], 4))\n  features[:, 0] = data['u'] - data['g']\n  features[:, 1] = data['g'] - data['r']\n  features[:, 2] = data['r'] - data['i']\n  features[:, 3] = data['i'] - data['z']\n  targets = data['redshift']\n  return features, targets\n\n# paste your median_diff function here\ndef median_diff(predicted, actual):\n  return np.median(np.abs(predicted - actual))\n\n# Complete the following function\ndef accuracy_by_treedepth(features, targets, depths):\n  # split the data into testing and training sets\n  split = features.shape[0]//2\n  train_features, test_features = features[:split], features[split:]\n  train_targets, test_targets = targets[:split], targets[split:]\n\n  # Initialise arrays or lists to store the accuracies for the below loop\n  train_diffs = []\n  test_diffs = []\n\n  # Loop through depths\n  for depth in depths:\n    # initialize model with the maximum depth. \n    dtr = DecisionTreeRegressor(max_depth=depth)\n\n    # train the model using the training set\n    dtr.fit(train_features, train_targets)\n\n    # Get the predictions for the training set and calculate their med_diff\n    predictions = dtr.predict(train_features)\n    train_diffs.append(median_diff(train_targets, predictions))\n\n    # Get the predictions for the testing set and calculate their med_diff\n    predictions = dtr.predict(test_features)\n    test_diffs.append(median_diff(test_targets, predictions))\n        \n  # Return the accuracies for the training and testing sets\n  return train_diffs, test_diffs    \n\nif __name__ == \"__main__\":\n  data = pd.read_csv('../input/finals1/opticaldatafinals_SDSS.csv')\n  features, targets = get_features_targets(data)\n\n  # Generate several depths to test\n  tree_depths = [i for i in range(1, 36, 2)]\n\n  # Call the function\n  train_med_diffs, test_med_diffs = accuracy_by_treedepth(features, targets, tree_depths)\n  print(\"Depth with lowest median difference : {}\".format(tree_depths[test_med_diffs.index(min(test_med_diffs))]))\n    \n  # Plot the results\n  train_plot = plt.plot(tree_depths, train_med_diffs, label='Training set')\n  test_plot = plt.plot(tree_depths, test_med_diffs, label='Validation set')\n  plt.xlabel(\"Maximum Tree Depth\")\n  plt.ylabel(\"Median of Differences\")\n  plt.legend()\n  plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1><center> KFold Cross Validation</center></h1>\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import KFold\nfrom sklearn.tree import DecisionTreeRegressor\n\n\ndef get_features_targets(data):\n  features = np.zeros((data.shape[0], 4)) #n lines, 4 columns\n  features[:,0] = data['u'] - data['g']\n  features[:,1] = data['g'] - data['r']\n  features[:,2] = data['r'] - data['i']\n  features[:,3] = data['i'] - data['z']\n  targets = data['redshift']\n  return (features, targets)\n\ndef median_diff(predicted, actual):\n  diff = np.median(np.absolute(predicted - actual))\n  return diff\n\n# complete this function\ndef cross_validate_model(model, features, targets, k):\n  kf = KFold(n_splits=k, shuffle=True)\n\n  # initialise a list to collect median_diffs for each iteration of the loop below\n  mediandiffs = []\n  \n  for train_indices, test_indices in kf.split(features):\n    train_features, test_features = features[train_indices], features[test_indices]\n    train_targets, test_targets = targets[train_indices], targets[test_indices]\n    \n    # fit the model for the current set\n    model.fit(train_features, train_targets)\n    \n    # predict using the model\n    predictions = model.predict(test_features)\n\n    # calculate the median_diff from predicted values and append to results array\n    mediandiffs.append(median_diff(test_targets, predictions))\n \n  # return the list with your median difference values\n  return mediandiffs\n\nif __name__ == \"__main__\":\n  data = pd.read_csv('../input/finals1/opticaldatafinals_SDSS.csv')\n  features, targets = get_features_targets(data)\n\n  # initialize model with a maximum depth of 19\n  dtr = DecisionTreeRegressor(max_depth=19)\n\n  # call your cross validation function\n  diffs = cross_validate_model(dtr, features, targets, 10)\n\n  # Print the values\n  print('Differences: {}'.format(', '.join(['{:.3f}'.format(val) for val in diffs])))\n  print('Mean difference: {:.3f}'.format(np.mean(diffs)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" <h2><center>KFold Cross Validated Predictions</h2></center>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import KFold\nfrom sklearn.tree import DecisionTreeRegressor\n\n# paste your get_features_targets function here\ndef get_features_targets(data):\n  features = np.zeros((data.shape[0], 4))\n  features[:, 0] = data['u'] - data['g']\n  features[:, 1] = data['g'] - data['r']\n  features[:, 2] = data['r'] - data['i']\n  features[:, 3] = data['i'] - data['z']\n  targets = data['redshift']\n  return features, targets\n\n# paste your median_diff function here\ndef median_diff(predicted, actual):\n  return np.median(np.abs(predicted - actual))\n\n# complete this function\ndef cross_validate_predictions(model, features, targets, k):\n  kf = KFold(n_splits=k, shuffle=True)\n\n  # declare an array for predicted redshifts from each iteration\n  all_predictions = np.zeros_like(targets)\n\n  for train_indices, test_indices in kf.split(features):\n    # split the data into training and testing\n    train_features, test_features = features[train_indices], features[test_indices]\n    train_targets, test_targets = targets[train_indices], targets[test_indices]\n    \n    # fit the model for the current set\n    model.fit(train_features, train_targets)\n        \n    # predict using the model\n    predictions = model.predict(test_features)\n        \n    # put the predicted values in the all_predictions array defined above\n    all_predictions[test_indices] = predictions\n\n  # return the predictions\n  return all_predictions\n\n\nif __name__ == \"__main__\":\n  data = pd.read_csv('../input/finals1/opticaldatafinals_SDSS.csv')\n  features, targets = get_features_targets(data)\n\n  # initialize model\n  dtr = DecisionTreeRegressor(max_depth=19)\n\n  # call your cross validation function\n  predictions = cross_validate_predictions(dtr, features, targets, 10)\n\n  # calculate and print the rmsd as a sanity check\n  diffs = median_diff(predictions, targets)\n  print('Median difference: {:.3f}'.format(diffs))\n\n  # plot the results to see how well our model looks\n  plt.scatter(targets, predictions, s=0.4)\n  plt.xlim((0, targets.max()))\n  plt.ylim((0, predictions.max()))\n  plt.xlabel('Measured Redshift')\n  plt.ylabel('Predicted Redshift')\n  plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1><center>Splitting the train and test sets</center></h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ndata = pd.read_csv('../input/finals1/opticaldatafinals_SDSS.csv',delimiter=\",\")\n\n  \n\n  # split the data using your function\ntraining,testing = train_test_split(data, test_size = 0.7,random_state=0)\n\n  # print the key values\nprint('Number data galaxies:', len(data))\nprint(test_size)\nprint('Number of galaxies in training set:', len(training))\nprint('Number of galaxies in testing set:', len(testing))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1><center>Generating features and targets</center></h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n\ndata = pd.read_csv('../input/finals1/opticaldatafinals_SDSS.csv')\n\n\ndef generate_features_targets(data):\n  # complete the function by calculating the concentrations\n\n  targets = data['class']\n\n  features = np.empty(shape=(len(data), 13))\n  features[:, 0] = data['u-g']\n  features[:, 1] = data['g-r']\n  features[:, 2] = data['r-i']\n  features[:, 3] = data['i-z']\n  features[:, 4] = data['ellipticity']\n  features[:, 5] = data['mCr4_u']\n  features[:, 6] = data['mCr4_g']\n  features[:, 7] = data['mCr4_r']\n  features[:, 8] = data['mCr4_i']\n  features[:, 9] = data['mCr4_z']\n\n  # fill the remaining 3 columns with concentrations in the u, r and z filters\n  # concentration in u filter\n  features[:, 10] = data['petroR50_u']/data['petroR90_u']\n  # concentration in r filter\n  features[:, 11] = data['petroR50_r']/data['petroR90_r']\n  # concentration in z filter\n  features[:, 12] = data['petroR50_z']/data['petroR90_z']\n\n  return features, targets\n\n\nif __name__ == \"__main__\":\n  data = pd.read_csv('../input/finals1/opticaldatafinals_SDSS.csv')\n\n  features, targets = generate_features_targets(data)\n\n  # Print the shape of each array to check the arrays are the correct dimensions. \n  print(\"Features shape:\", features.shape)\n  print(\"Targets shape:\", targets.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1><center>Train the decision tree classifier</center></h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport math\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\n\n\n\n\n\n\n\ndef generate_features_targets(data):\n    targets = data['class1']\n    features = np.empty(shape=(len(data), 13))\n    features[:, 0] = data['u-g']\n    features[:, 1] = data['g-r']\n    features[:, 2] = data['r-i']\n    features[:, 3] = data['i-z']\n    features[:, 5] = data['mCr4_u']\n    features[:, 6] = data['mCr4_g']\n    features[:, 7] = data['mCr4_r']\n    features[:, 8] = data['mCr4_i']\n    features[:, 9] = data['mCr4_z']\n    features[:, 10] = data['petroR50_u']/data['petroR90_u']\n    features[:, 11] = data['petroR50_r']/data['petroR90_r']\n    features[:, 12] = data['petroR50_z']/data['petroR90_z']\n    return features, targets\n\n# complete this function by splitting the data set and training a decision tree classifier\ndef dtc_predict_actual(data):\n    training,testing = train_test_split(data, test_size = 0.7)\n    features_training, targets_training = generate_features_targets(training)\n    features_testing, targets_testing = generate_features_targets(testing)\n    dtc = DecisionTreeClassifier()\n    dtc.fit(features_training, targets_training)\n    predictions = dtc.predict(features_testing)\n    return predictions, targets_testing\n\n\nif __name__ == '__main__':\n  \n  data = pd.read_csv('../input/finals1/opticaldatafinals_SDSS.csv')  \n  predicted_class, actual_class = dtc_predict_actual(data)\n\n  # Print some of the initial results\nprint(\"Some initial results...\\n   predicted,  actual\")\nfor i in range(243):\n    print(\"{}. {}, {}\".format(i, predicted_class[i], actual_class[i]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<center><h1> Accuracy in classification</h1></center>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.tree import DecisionTreeClassifier\nimport itertools\n\n\ndef generate_features_targets(data):\n    output_targets = np.empty(shape=(len(data)), dtype='<U20')\n    output_targets[:] = data['class1']\n\n    input_features = np.empty(shape=(len(data), 13))\n    input_features[:, 0] = data['u-g']\n    input_features[:, 1] = data['g-r']\n    input_features[:, 2] = data['r-i']\n    input_features[:, 3] = data['i-z']\n    input_features[:, 4] = data['ellipticity']\n    input_features[:, 5] = data['mCr4_u']\n    input_features[:, 6] = data['mCr4_g']\n    input_features[:, 7] = data['mCr4_r']\n    input_features[:, 8] = data['mCr4_i']\n    input_features[:, 9] = data['mCr4_z']\n    input_features[:, 10] = data['petroR50_u'] / data['petroR90_u']\n    input_features[:, 11] = data['petroR50_r'] / data['petroR90_r']\n    input_features[:, 12] = data['petroR50_z'] / data['petroR90_z']\n\n    return input_features, output_targets\n\n\n\ndef plot_confusion_matrix(cm, classes,normalize=False,title='Confusion matrix',cmap=plt.cm.Blues):\n    \"\"\" This function prints and plots the confusion matrix.Normalization can be applied by setting `normalize=True` \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, \"{}\".format(cm[i, j]),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True Class')\n    plt.xlabel('Predicted Class')\n\n\ndef calculate_accuracy(predicted, actual):\n    correct = 0\n  \n  # iterate over the two lists simultaneously\n    for p,a in zip(predicted,actual):\n        if p == a:\n            correct += 1\n  \n    accuracy = correct / len(actual)\n    return accuracy\n\n\nif __name__ == \"__main__\":\n    data = pd.read_csv('../input/finals1/opticaldatafinals_SDSS.csv') \n\n  # split the data\n    features, targets = generate_features_targets(data)\n\n      # train the model to get predicted and actual classes\n    dtc = DecisionTreeClassifier()\n    predicted = cross_val_predict(dtc, features, targets, cv=10)\n\n    # calculate the model score using your function\n    model_score = calculate_accuracy(predicted, targets)\n    print(\"Our accuracy score:\", model_score)\n\n    # calculate the models confusion matrix using sklearns confusion_matrix function\n    class_labels = list(set(targets))\n    model_cm = confusion_matrix(y_true=targets, y_pred=predicted, labels=class_labels)\n\n    # Plot the confusion matrix using the provided functions.\n    plt.figure()\n    plot_confusion_matrix(model_cm, classes=class_labels, normalize=False)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}